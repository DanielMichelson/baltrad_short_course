{
 "metadata": {
  "name": "",
  "signature": "sha256:51b9dac1503d76844c27246cfa27139f98355674cf15328f6e5a2ee3cfb5da99"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "BALTRAD parallel processing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The default VM setup is to use a single CPU core. In order to demonstrate the power of parallel processing, you must first determine whether your physical hardware has more than a single core.\n",
      "\n",
      "On Linux this is done in the terminal with the 'nproc' command.\n",
      "\n",
      "On Mac this is done in the terminal with the 'sysctl -n hw.ncpu' command.\n",
      "\n",
      "On Windows this is done graphically using the Task Manager's Performance tab.\n",
      "\n",
      "We want tune our VM to harness the power of several CPUs. This means we will add configuration to the 'Vagrantfile' and then restart the VM. The Vagrantfile is in the 'oss_weather_radar_vm' directory. Edit it just below line 18 which reads:\n",
      "\n",
      "    vb.customize [\"modifyvm\", :id, \"--memory\", \"2048\"]\n",
      " \n",
      "Add the following two lines:\n",
      " \n",
      "    vb.customize [\"modifyvm\", :id, \"--ioapic\", \"on\"]\n",
      "    \n",
      "and assuming a quad-core CPU with 8 logical cores:\n",
      "    \n",
      "    vb.customize [\"modifyvm\", :id, \"--cpus\", \"8\"]\n",
      "\n",
      "Then restart your VM:\n",
      "\n",
      "    oss_weather_radar_vm baltrad$ vagrant reload\n",
      "\n",
      "Log back in:\n",
      "\n",
      "    oss_weather_radar_vm baltrad$ vagrant ssh\n",
      "    \n",
      "and restart your notebook server:\n",
      "\n",
      "    vagrant@vagrant-ubuntu-trusty-64:~$ ./start_notebook.sh\n",
      "\n",
      "RELOAD THIS PAGE!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Verify from Python the number of CPU cores at our disposal"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "print \"We have %i cores to play with!\" % multiprocessing.cpu_count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yay! Now we're going to set up some rudimentary functionality that will allow us to distribute a processing load among our cores."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define a generator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import _raveio, odc_polarQC\n",
      "\n",
      "# Specify the processing chain\n",
      "odc_polarQC.algorithm_ids = [\"ropo\", \"beamb\", \"radvol-att\", \"radvol-broad\", \"rave-overshooting\", \"qi-total\"]\n",
      "\n",
      "# Run processing chain on a single file. Return an output file string.\n",
      "def generate(file_string):\n",
      "    rio = _raveio.open(file_string)\n",
      "\n",
      "    pvol = rio.object\n",
      "    pvol = odc_polarQC.QC(pvol)\n",
      "    rio.object = pvol\n",
      "    \n",
      "    # Derive an output file name\n",
      "    path, fstr = os.path.split(file_string)\n",
      "    ofstr = os.path.join(path, 'qc_'+fstr)\n",
      "    \n",
      "    rio.save(ofstr)\n",
      "    return ofstr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feed the generator, sequentially"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob, time\n",
      "\n",
      "ifstrs = glob.glob(\"data/se*.h5\")\n",
      "before = time.time()\n",
      "for fstr in ifstrs:\n",
      "    print fstr, generate(fstr)\n",
      "after = time.time()\n",
      "\n",
      "print \"Processing time: %3.2f seconds\" % (after-before)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mental note: repeat once!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Multiprocess the generator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Both input and output are a list of file strings\n",
      "def multi_generate(fstrs, procs=None):\n",
      "    pool = multiprocessing.Pool(procs)  # Pool of processors. Defaults to all available logical cores\n",
      "\n",
      "    results = []\n",
      "    # chunksize=1 means feed a process new jobs as soon as they are idle.\n",
      "    # In our case, this restricts the queue to one place which is faster.\n",
      "    r = pool.map_async(generate, fstrs, chunksize=1, callback=results.append)\n",
      "    r.wait()\n",
      "\n",
      "    return results[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feed the monster, asynchronously!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "before = time.time()\n",
      "ofstrs = multi_generate(ifstrs)\n",
      "after = time.time()\n",
      "\n",
      "print \"Processing time: %3.2f seconds\" % (after-before)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}